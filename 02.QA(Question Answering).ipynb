{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"F4C5t4J9nuBS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648013994861,"user_tz":-540,"elapsed":8157,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"5d17b25a-4297-4d48-f493-a25ae7857779"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 76.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 71.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uvrQTvcDnYQK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648014026850,"user_tz":-540,"elapsed":18293,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"7bebf37b-925a-4bb9-80a0-85637dce8b99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","import torch\n","from torch.optim import Adam, AdamW\n","from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n","from transformers import BertTokenizer, BertTokenizerFast, BertForQuestionAnswering\n","from transformers import get_linear_schedule_with_warmup\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import  f1_score\n","\n","import gc\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["%cd /content/gdrive/My Drive/NLP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d14Nv2g-2nH0","executionInfo":{"status":"ok","timestamp":1648014026850,"user_tz":-540,"elapsed":5,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"d8541d5f-9f61-496a-e1d6-e8c3afefbb34"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/NLP\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vQd9P24Cn1yb","executionInfo":{"status":"ok","timestamp":1648014028105,"user_tz":-540,"elapsed":1258,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f82ab51-fb05-4256-81bb-2c718073564e"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-23 05:40:26--  https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\n","Resolving korquad.github.io (korquad.github.io)... 185.199.108.153, 185.199.109.153, 185.199.111.153, ...\n","Connecting to korquad.github.io (korquad.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 38527475 (37M) [application/json]\n","Saving to: ‘KorQuAD_v1.0_train.json’\n","\n","KorQuAD_v1.0_train. 100%[===================>]  36.74M  76.0MB/s    in 0.5s    \n","\n","2022-03-23 05:40:27 (76.0 MB/s) - ‘KorQuAD_v1.0_train.json’ saved [38527475/38527475]\n","\n","--2022-03-23 05:40:27--  https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json\n","Resolving korquad.github.io (korquad.github.io)... 185.199.108.153, 185.199.109.153, 185.199.111.153, ...\n","Connecting to korquad.github.io (korquad.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3881058 (3.7M) [application/json]\n","Saving to: ‘KorQuAD_v1.0_dev.json’\n","\n","KorQuAD_v1.0_dev.js 100%[===================>]   3.70M  --.-KB/s    in 0.05s   \n","\n","2022-03-23 05:40:27 (69.5 MB/s) - ‘KorQuAD_v1.0_dev.json’ saved [3881058/3881058]\n","\n"]}],"source":["!wget https://korquad.github.io/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n","!wget https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dmzqXLws2Wl1","executionInfo":{"status":"ok","timestamp":1648014028105,"user_tz":-540,"elapsed":2,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jNJWh_1LbCsH","executionInfo":{"status":"ok","timestamp":1648014028105,"user_tz":-540,"elapsed":2,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["def data_load(path):\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    contexts = []\n","    questions = []\n","    answers = [] \n","    start_ids = []\n","    end_ids = []\n","\n","    for datas in squad_dict['data']:\n","        for paragraphs in datas['paragraphs']:\n","            context = paragraphs['context']\n","            for qas in paragraphs['qas']:\n","                question = qas['question']\n","                for answer in qas['answers']:\n","                    contexts.append(context)\n","                    questions.append(question)\n","                    answers.append(answer['text'])\n","\n","                    start_index = answer['answer_start']\n","                    start_ids.append(start_index)\n","\n","                    answer['text'] = answer['text'].rstrip()\n","                    \n","                    end_index = start_index + len(answer['text'])\n","                    end_ids.append(end_index)                  \n","\n","    return pd.DataFrame({'contexts' : contexts, 'questions' : questions, 'answers' : answers, 'start_ids': start_ids,'end_ids': end_ids})"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4oQehYoVbShA","executionInfo":{"status":"ok","timestamp":1648014029487,"user_tz":-540,"elapsed":1384,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["train_df = data_load('KorQuAD_v1.0_train.json')\n","valid_df = data_load('KorQuAD_v1.0_dev.json')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"o6aIqQAKo4Na","executionInfo":{"status":"ok","timestamp":1648014029487,"user_tz":-540,"elapsed":5,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["def qa_preprocess(df, batch_size=16, method='train'):\n","  if method == 'train' or method == 'valid':    \n","      batch_input = tokenizer(df['contexts'].tolist(), df['questions'].tolist(), truncation=True, padding=True)\n","\n","      start_ids = df['start_ids'].tolist()\n","      end_ids = df['end_ids'].tolist()\n","\n","      start_positions = [batch_input.char_to_token(i, start_ids[i]) for i in range(len(start_ids))]\n","      end_positions = [batch_input.char_to_token(i, end_ids[i]-1) for i in range(len(end_ids))]\n","      deleting_list = [i for i, v in enumerate(end_positions) if v == None]\n","          \n","      batch_input.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","     \n","      batch_input = {key : np.delete(np.array(value), deleting_list, axis=0) for key, value in batch_input.items()}\n","      batch_input = {key : torch.tensor(value.astype(int)) for key, value in batch_input.items()}\n","\n","      dataset = TensorDataset(batch_input['input_ids'], batch_input['attention_mask'], batch_input['token_type_ids'], batch_input['start_positions'], batch_input['end_positions'])\n","      if method == 'train':\n","        dataset_sampler = RandomSampler(dataset)\n","        dataloader = DataLoader(dataset, sampler=dataset_sampler, batch_size=batch_size)\n","      elif method == 'valid':\n","        dataloader = DataLoader(dataset, batch_size=batch_size)\n","      return dataloader, deleting_list\n","\n","  elif method == 'test':\n","      batch_input = tokenizer(df['contexts'].tolist(), df['questions'].tolist(), truncation=True, padding=True)\n","      batch_input = {key : torch.tensor(value) for key, value in batch_input.items()}\n","\n","      dataset = TensorDataset(batch_input['input_ids'], batch_input['attention_mask'], batch_input['token_type_ids'])\n","      dataloader = DataLoader(dataset, batch_size=batch_size)\n","\n","  return dataloader"]},{"cell_type":"markdown","metadata":{"id":"DtCOpE3qpr-J"},"source":["# model training\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3jEr_ZSfqHRB","executionInfo":{"status":"ok","timestamp":1648014029487,"user_tz":-540,"elapsed":4,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["def train_one_epoch(optimizer, scheduler, dataloader,accumulation=2):\n","    model.train()\n","\n","    running_loss = 0.0\n","    train_losses = []\n","\n","    for ids, batchs in enumerate(tqdm(dataloader)):\n","        batch = tuple(b.to(device) for b in batchs)\n","\n","        inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","                \"start_positions\": batch[3],\n","                \"end_positions\": batch[4],\n","            }\n","\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(**inputs)\n","\n","        (outputs.loss/accumulation).backward()\n","        running_loss += outputs.loss.item()\n","\n","        del inputs\n","        if (ids+1) % accumulation: # enumerate의 ids\n","            continue\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        train_losses.append(running_loss / accumulation)\n","\n","    train_loss = sum(train_losses) / len(train_losses)\n","    \n","    return train_loss"]},{"cell_type":"markdown","metadata":{"id":"eIYgqtdZqHTE"},"source":["# model_evaluate"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"QPEOSIRNrf2r","executionInfo":{"status":"ok","timestamp":1648014029487,"user_tz":-540,"elapsed":3,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["def evaluate_one_epoch(dataloader,accumulation=2):\n","    model.eval()\n","\n","    start_preds = []\n","    end_preds = []\n","    input = []\n","\n","    for ids, batchs in enumerate(tqdm(dataloader)):\n","        batch = tuple(b.to(device) for b in batchs)\n","\n","        inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2]\n","            }\n","\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        # del inputs\n","        # if (ids+1) % accumulation:\n","        #     continue\n","\n","        # CPU로 데이터 이동\n","        start_pred = outputs['start_logits'].detach().cpu()\n","        end_pred = outputs['end_logits'].detach().cpu()\n","\n","        input.append(inputs['input_ids'].detach().cpu())\n","        start_preds.append(start_pred)\n","        end_preds.append(end_pred)\n","\n","    input = torch.cat(input, dim=0).tolist()\n","    start_preds = torch.cat(start_preds, dim=0).argmax(dim=-1).tolist()\n","    end_preds = torch.cat(end_preds, dim=0).argmax(dim=-1).tolist()\n","\n","    answer = [tokenizer.decode(input[s:e+1]) for input, s, e in zip(input,start_preds,end_preds)]\n","\n","    return answer"]},{"cell_type":"markdown","metadata":{"id":"wGTP-kmurgcu"},"source":["# QA Model"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"e1UAY09vqHU1","executionInfo":{"status":"ok","timestamp":1648014029488,"user_tz":-540,"elapsed":4,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["def qa_model(train_data, dev_data,lr=1e-4,epochs = 4, batch_size=32,accumulation=2, bert='klue/bert-base', save=True, path='bert_qa'):\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    global tokenizer\n","    tokenizer = BertTokenizerFast.from_pretrained(bert)\n","\n","    global model,device\n","    model = BertForQuestionAnswering.from_pretrained(bert)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    train_dataloader,train_delete = qa_preprocess(train_data, batch_size=batch_size//accumulation, method = 'train')\n","    val_dataloader,val_delete = qa_preprocess(dev_data, batch_size=batch_size//accumulation, method = 'valid')\n","    print('')\n","    print('Preprocess Compelete')\n","    print('')\n","\n","    optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n","\n","    total_steps = len(train_dataloader) * epochs\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                num_warmup_steps = 0,\n","                                                num_training_steps = total_steps)\n","\n","    print('')\n","    print('Model Training Start')\n","    print(f'Epochs : {epochs} / Learning Rate : {str(lr)} / Batch Size : {batch_size}')\n","    print('')\n","\n","    loss = []\n","    f1 = []\n","    for epoch in range(1,epochs+1):\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(f\"epoch = {epoch}\")\n","\n","        train_lossloss = train_one_epoch(optimizer, scheduler, dataloader=train_dataloader,accumulation=2)\n","        preds = evaluate_one_epoch(dataloader=val_dataloader,accumulation=2)\n","\n","        valid_f1 = f1_score(dev_data.drop(val_delete,axis=0)['answers'].tolist(),preds,average='micro')\n","        f1.append(valid_f1)\n","\n","        print(f'epoch : {epoch} / loss : {train_lossloss} / f1_score : {valid_f1}')\n","\n","        if save:\n","            model.save_pretrained(f'models/{path}')\n","            tokenizer.save_pretrained(f'models/{path}')\n","            print('Model Save')\n","    \n","    print('')\n","    print(\"Training Complete!\")\n","\n","    return {'loss':loss,'f1 score':f1}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nxL1ftMq8vG"},"outputs":[],"source":["score,preds = qa_model(train_df, valid_df, lr = 1e-5,epochs=4,batch_size=32,accumulation=2, bert='klue/bert-base', path='qa_test')"]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"nsIduLJJfZX2"}},{"cell_type":"code","source":["def QA_test(test_data, batch_size=32,bert='QA'):\n","    global tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(f'klue/bert-base')\n","    test_dataloader = qa_preprocess(test_data, batch_size=batch_size, method='test')\n","\n","    global model, device\n","    model = BertForQuestionAnswering.from_pretrained(f'models/{bert}')\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    answer = evaluate_one_epoch(dataloader=test_dataloader)\n","\n","    new_df = valid_df[['contexts','questions']].copy()\n","    new_df['answers'] = answer\n","    \n","    return  new_df"],"metadata":{"id":"hfZ_SA2NWeQx","executionInfo":{"status":"ok","timestamp":1648014029488,"user_tz":-540,"elapsed":3,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df = QA_test(valid_df, batch_size=32,bert='qa_test')"],"metadata":{"id":"IqEhMmcEUJ4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample = df.sample(5)\n","\n","for i in range(len(sample)):\n","    print('context : ', sample['contexts'].tolist()[i])\n","    print('questions : ', sample['questions'].tolist()[i])\n","    print('answers : ', sample['answers'].tolist()[i])\n","    print('')"],"metadata":{"id":"adMSENuNhkDu","executionInfo":{"status":"ok","timestamp":1648011069655,"user_tz":-540,"elapsed":7,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be032246-0595-4a7b-979d-08f2e11aadc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["context :  2017년 2월 13일 오전 9시경 김정남은 말레이시아 세팡에 위치한 쿠알라룸푸르 국제공항에서 무언가를 맨손에 묻힌 여성 2명이 얼굴을 문지르고 얼마 후 사망하였다. 보툴리눔으로 죽었다는 설도 나왔고, 독극물 스프레이를 맞고 사망하였다는 설도 있다. 또한 일부는 독침으로 죽었다는 가설도 있다고 한다. 김정남 암살은 김정은이 권력을 승계받은 2011년 다음해 인 2012년 초 부터 진행되었으며, 정찰총국 등 북한 정보당국의 최순위 목표였다고 국가정보원이 밝혔다. 또한 국가정보원은 2012년 4월 김정남이 김정은 위원장에게 “살려달라”는 내용의 서신을 보낸 사실도 공개하였다. 2017년 2월 19일 말레이시아 경찰은 공식 브리핑을 통해 암살을 실행한 인도네시아,베트남 출신 여성 2명을 배후에서 사주한 일당 4명이 모두 조선민주주의인민공화국 국적이라고 발표하였다.\n","questions :  김정남을 살해한 배후와 사주한 일당의 국적은?\n","answers :  조선민주주의인민공화국\n","\n","context :  1977년 입사하여 원액2과에서 7년간 근무하고 1983년 퇴사한 김봉환은 1990년 10월 30일 초진으로 이황화탄소 중독판정을 받고 회사에 산재요양신청을 냈으나 거부당했다. 1991년 1월 5일 김봉환은 직업병 증세인 정신분열로 인해 사망하였다. 김봉환이 활동하던 '원진직업병피해노동자협의회'(이하 원노협)는 이황화탄소 중독 여부를 검진 받지 못하고 사망한 데에 대한 책임을 물어 사업주를 처벌하고 부검 담당 검사에게 의뢰하여 원진직업병으로 인한 사망 여부를 판정해 줄 것을 노동부 측에 요구하였다. 그러나 병리학 검사를 의뢰받은 고려대학교의 비협조적인 태도와 회사와 사측 추천 의사들의 무성의로 사건을 제대로 마무리 짓지 못하였다. 유족과 원노협 회원들은 영결식을 위한 회사 출입을 봉쇄당하여 회사 정문 앞에서 시신투쟁을 벌이고 평일에는 대책위와 조합원을 중심으로 주말에는 수도권의 노동자와 사회단체, 학생들의 지지와 지원으로 연대집회를 열어 거리정치투쟁을 하였다. 연일 계속되는 언론보도와 거리투쟁으로 발전한 조합원들의 열기가 정치권이 움직이게 했고 마침내 5월 21일 노동부와 회사를 굴복시켰다. 137일간의 긴 투쟁은 이황화탄소에 대한 업무상 재해인정기준안을 만들고 퇴직직업병 판정자 평균임금 산정방법의 개정을 통한 특례적용이라는 성과를 이루었다.\n","questions :  김봉환이 원진레이온의 입사시기는?\n","answers :  1977년\n","\n","context :  평공 치세 초기에는 이웃한 정나라가 초나라와 진나라 사이를 오갔고, 송나라는 줄곧 진나라 편에 섰기에 진나라의 통솔을 받아 정나라를 공격했으며 초나라의 편을 든 정나라의 공격을 받았다. 평공 12년(기원전 564년)에 진나라와 함께 정나라를 공격했다. 평공 13년(기원전 563년) 6월에는 초나라 영윤 자낭(子囊)과 정나라 자이(子耳)의 공격을 받아 위나라의 구원을 받았으며, 7월에는 자낭과 자이가 노나라를 치다 돌아오면서 송나라의 소읍을 공격, 함락시켰다. 평공은 진 도공이 송나라를 구원하기 위해 연 회맹에 참석하고 정나라 보복 공격에도 참여했으나, 진 도공의 이 둘째 출병은 초나라 공자 정(公子貞 = 자낭)이 정나라를 구원하자 일단 물러서면서 정나라는 다시 초나라 편에 붙었다. 평공 14년(기원전 562년)에는 초나라와 정나라의 연합 공격을 받았다. 그러나 이 공격은 정나라가 진나라에 귀순하기 위해 진나라가 초나라에 노를 격발하여 초나라를 크게 쳐 초나라를 완전히 꺾어주기를 기대한 수작이었다. 4월, 평공은 진 도공이 다시 정나라를 토벌하기 위해 소집한 제후연합군에 참여했고, 상술이 먼저 정나라 동문 밖에 주둔했다. 정나라는 6월에 제후연합군에 화친을 청했다. 초나라에서는 자낭을 보내고 또 진나라에 원군을 청해 정나라를 치니, 정나라는 바로 초 · 진나라에 항복하고 또 송나라를 쳤다. 평공은 진 도공이 9월에 다시 소집한 제후연합군에 참여해 정나라를 공격했다. 이번에는 초나라가 정나라를 구원하지 못해, 결국 정나라는 진 도공에게 넘어갔다. 그 때문에 송나라는 평공 15년(기원전 561년)에 초나라 자낭과 진나라 서장 무지(無地)에게 보복 공격을 당했다.\n","questions :  평공 14년에 송나라는 초나라와 어떤 나라의 연합군에게 공격받는가?\n","answers :  정나라\n","\n","context :  중국에 있어서 법원(法源)은, 중화인민공화국 헌법을 정점으로 하여, 법률, 행정법규, 지방성(地方性)법규, 자치조례 · 단행(単行)조례, 행정규칙 등이 있다. 입법법(立法法)은, 이들 법원의 서열과 상호저촉의 경우의 처리를 규정한다. 입법법은, 국가주권, 국가조직의 형성 · 조직 · 권한, 범죄과 형벌, 민사의 기본적 제도, 소송 · 중재제도 등은 원칙적으로 법률에 의하여 한다고 규정한다. “기본적 법률”(그 개념을 명확히 정의한 규정은 없다.)은 전국인민대표대회(전인대)가 제정하고, 그 외의 법률은 전인대 상무위원회가 제정한다. 이어서, 국가주석은 전인대 및 전인대 상무위원회가 제정한 법률을 공포한다.(주석령, 主席令) 행정법규는, 국무원이 제정하는 것으로, 법률의 세칙과 행정 관리에 관하여 헌법 및 법률에 저촉되지 아니하는 한도에서 제정한다. 행정법규는, “○○조례”라는 명칭의 경우가 많으나, “◯◯변법(弁法)” 또는 “◯◯규정”이라는 명칭의 경우도 있다. 세제개혁, 경제제도개혁, 대외개방에 관한 사항에 대하여는, 국무원은 잠정조례 또는 잠정변법을 제정하는 권한을 가진다.\n","questions :  법원의 서열 및 상호저촉 등을 관장하는 법은 무엇인가?\n","answers :  입법법\n","\n","context :  8월 26일 이회창은 심대평 대표에 대한 총리 기용설과 관련, \"앞으로 이에 관한 이야기는 일체 나오지 않았으면 한다\"고 밝혔다. 이 총재는 이날 국회에서 열린 당5역회의에서 \"심 대표의 총리 기용 여부와 관련해 마치 당에 내분이 일어나는 것처럼 비쳐지고 있는 것은 매우 유감스러운 일\"이라고 말했다. 이 발언은 정치연대의 틀 없이 선진당 소속 의원이 내각에 참여할 수 없다는 기존 원칙을 강조한 것으로 보인다는 평가가 있다. 그는 또한 \"당직자들이 개인 의견을 말하는 것은 당에 전혀 도움이 되지 않는다\"며 \"외부의 추측과 풍문 때문에 쓸데없이 우리당 스스로 내분과 같은 양상으로 비쳐지는 것은 경계해야 한다\"고 지적했다. 이후 8월 30일 자유선진당 심대평 대표가 이회창 총재의 독선적 당 운영에 불만을 제기하면서 탈당하였다. 심 대표의 탈당으로 자유선진당과 창조한국당이 함께 구성한 교섭단체(선진과 창조의 모임)가 붕괴되었다. 탈당에 대해 이회창은 \"어려움을 함께 하면서 여기까지 왔는데 이렇게 돼서 안타깝고 가슴 아프다\" 고 말했다고 박선영 대변인이 전했다. 9월 3일 그가 자유선진당 세비기금 전달차 들른 대전 서구 둔산동 오페라웨딩에서 가진 기자회견에서 \"자유선진당이 원내교섭단체 지위를 잃었다고 해서 생명줄이 끊어진 것은 아니다\"며 \"우리는 17석을 갖고 최대한 맡은 일을 해낼 것이고, 원내교섭단체 구성도 모색할 것\"이라고 밝혔다. 또 심대평 대표의 국무총리 입각 반대 배경에 대해 \"심 전 대표가 국무총리에 입각하는 것은 현 정권의 한복판에 들어가는 것인데 과연 그렇게 했을 때 선진당이 그동안 반대해 온 '4대강 살리기 사업' 등을 강하게 비판하고 반대할 수 있겠느냐\"며 반문했다. 그는 그러면서 \"선진당이 미디어법 등 개별사안에 대해 다른 정당과 정책적으로 공조하는 것과 총리 입각 등 큰 틀에서 공조하는 것은 차원이 전혀 다르다\"고 강조했다. 자유선진당이 이회창 총재한테 너무 많은 권한이 집중돼 있다는 지적이 있는데 일선에 후퇴할 생각이 없느냐는 질문에는 \"총재 자리에서 사퇴하라는 얘기는 여기와서 처음 들어봤다\"고 일축한 뒤 \"나는 그동안 모든 일을 철저하게 토론을 통해 결정했다. 내가 일방적으로 모든 일을 결정해 왔다는 것에 대해 아무도 동의하지 않을 것\"이라고 말했다. 그는 심 전 대표에 대한 복당 요구가 '립서비스'에 불과하다는 지적에 대해 \"결코 립서비스가 아니다. 직접 찾아뵙고 싶었지만 잘 안됐고, 전화연락도 안된다는 얘기를 들었다\"며 \"진심으로 돌아오기를 바란다\"고 말했다. 이밖에 이 총재는 무소속 이인제 의원과 염홍철 전 대전시장의 영입 여부에 대해 \"이 자리에서 특정인을 언급하는 것은 적절치 않은 만큼 언급하지 않겠다\"며 말을 아꼈다.\n","questions :  8월 30일 누가 불만을 제기 했나?\n","answers :  심대평\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"03-QA(Question Answering).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}