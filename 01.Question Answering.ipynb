{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8780,"status":"ok","timestamp":1647693667034,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"},"user_tz":-540},"id":"gcl7v9Exyfiu","outputId":"62a0976a-ac35-41b2-b15b-b28c8e75cfdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 75.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 78.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3343,"status":"ok","timestamp":1647697830266,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"},"user_tz":-540},"id":"YQwOWZ6RygSE","outputId":"1b813605-f86f-4fae-8177-6da74f6af169"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","import torch\n","from torch.optim import Adam, AdamW\n","from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n","from transformers import BertTokenizer, BertTokenizerFast, BertForQuestionAnswering\n","from transformers import get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import  f1_score\n","\n","import gc\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/goorm/02.qa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50xv_OL0D90B","executionInfo":{"status":"ok","timestamp":1647693706264,"user_tz":-540,"elapsed":476,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"880ba31c-6277-4d58-c438-df5871770e5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/goorm/02.qa\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OE2tLV9byiJT"},"outputs":[],"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"markdown","source":["# Data Load"],"metadata":{"id":"d2YoE_hzc8ES"}},{"cell_type":"code","execution_count":113,"metadata":{"id":"3IlN1EiAyfeU","executionInfo":{"status":"ok","timestamp":1647697840885,"user_tz":-540,"elapsed":354,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["# 제공된 데이터 로드 \n","def data_load(path, test = False):\n","    with open('datas/'+path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","\n","    contexts = []\n","    questions = []\n","    answers = [] \n","    guids = []\n","    start_ids = []\n","    end_ids = []\n","\n","    for datas in squad_dict['data']:\n","        for paragraphs in datas['paragraphs']:\n","            context = paragraphs['context']\n","            for qas in paragraphs['qas']:\n","                question = qas['question']\n","                guid = qas['guid']\n","\n","                contexts.append(context)\n","                questions.append(question)\n","                guids.append(guid)\n","\n","                if test == False:\n","                    answer = qas['answers'][0]\n","                    answers.append(answer['text'])\n","                    start_index = answer['answer_start']\n","                    start_ids.append(start_index)\n","                    \n","                    end_index = start_index + len(answer['text'])\n","                    end_ids.append(end_index)\n","\n","                    data = {'contexts' : contexts, 'questions' : questions, 'answers' : answers, 'start_ids': start_ids,'end_ids': end_ids}\n","                else:\n","                    data = {'contexts' : contexts, 'questions' : questions}\n","\n","\n","    return pd.DataFrame(data, columns=data.keys()),guids"]},{"cell_type":"code","execution_count":125,"metadata":{"id":"VCREWX19yfbS","executionInfo":{"status":"ok","timestamp":1647698247530,"user_tz":-540,"elapsed":366,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"outputs":[],"source":["# ai hub 데이터 로드\n","def aihub_data_load(path):\n","    with open('datas/'+path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    contexts = []\n","    questions = []\n","    answers = [] \n","    start_ids = []\n","    end_ids = []\n","\n","    for datas in squad_dict['data']:\n","        for paragraphs in datas['paragraphs']:\n","            context = paragraphs['context']\n","            for qas in paragraphs['qas']:\n","                question = qas['question']\n","                answer = qas['answers'][0]\n","                start_index = answer['answer_start']\n","                end_index = start_index + len(answer['text'])\n","\n","                contexts.append(context)\n","                questions.append(question)\n","                answers.append(answer['text'])                \n","                start_ids.append(start_index)\n","                end_ids.append(end_index)                  \n","\n","    data = {'contexts' : contexts, 'questions' : questions, 'answers' : answers, 'start_ids': start_ids,'end_ids': end_ids}\n","\n","    return pd.DataFrame(data,columns=data.keys())"]},{"cell_type":"code","source":["train_df = aihub_data_load('ko_nia_normal_squad_all.json')\n","valid = train_df.sample(frac = 0.1)\n","\n","train_df = train_df.drop(valid.index)\n","\n","valid_df, valid_guid = data_load('train.json')\n","valid_df = valid_df.append(valid)"],"metadata":{"id":"F8jIotPkyfW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tokenizer를 이용한 데이터 전처리"],"metadata":{"id":"3Jmk6WPAdKgy"}},{"cell_type":"code","execution_count":117,"metadata":{"executionInfo":{"elapsed":5045,"status":"ok","timestamp":1647697918313,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"},"user_tz":-540},"id":"9tkjPpdCyu81","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae49cc1e-4d23-43f0-b45b-a73506ebc9e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["path = 'klue/bert-base'\n","tokenizer = BertTokenizerFast.from_pretrained(path)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = BertForQuestionAnswering.from_pretrained(path)\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1ueVZPbyfRM"},"outputs":[],"source":["# method를 통해 train, valid, test에 맞게 데이터를 전처리\n","def qa_preprocess(df, batch_size=16, method='train'):\n","\n","    if method == 'train' or method == 'valid':\n","        batch_input = tokenizer(df['contexts'].tolist(), df['questions'].tolist(), truncation=True, padding=True)\n","\n","        start_ids = df['start_ids'].tolist()\n","        end_ids = df['end_ids'].tolist()\n","\n","        # input_ids에서 start position과 end position을 찾아주고 토크나이저의 max lnegth를 초과한다면 제거\n","        start_positions = [batch_input.char_to_token(i, start_ids[i]) for i in range(len(start_ids))]\n","        end_positions = [batch_input.char_to_token(i, end_ids[i]-1) for i in range(len(end_ids))]\n","        deleting_list = [i for i, v in enumerate(end_positions) if v == None]\n","            \n","        batch_input.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","        batch_input = {key : [v for ids, v in enumerate(value) if ids not in deleting_list] for key, value in batch_input.items()}\n","        batch_input = {key : torch.tensor(np.array(value,dtype=float).astype(int)) for key, value in batch_input.items()}\n","\n","        input_ids = batch_input['input_ids'] \n","        segments = batch_input['token_type_ids']\n","        masks = batch_input['attention_mask']\n","        start_ids = batch_input['start_positions']\n","        end_ids = batch_input['end_positions']\n","\n","        dataset = TensorDataset(input_ids, masks, segments, start_ids, end_ids)\n","        if method == 'train':\n","            dataset_sampler = RandomSampler(dataset)\n","            dataloader = DataLoader(dataset, sampler=dataset_sampler, batch_size=16)\n","        elif method == 'valid':\n","            dataloader = DataLoader(dataset, batch_size=batch_size)\n","        return dataloader, deleting_list\n","\n","    elif method == 'test':\n","        batch_input = tokenizer(df['contexts'].tolist(), df['questions'].tolist(), truncation=True, padding=True)\n","        batch_input = {key : torch.tensor(value) for key, value in batch_input.items()}\n","\n","        dataset = TensorDataset(batch_input['input_ids'], batch_input['attention_mask'], batch_input['token_type_ids'])\n","        dataloader = DataLoader(dataset, batch_size=batch_size)\n","\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaJV9p7Iy1y7"},"outputs":[],"source":["train_dataloader,train_delete = qa_preprocess(train_df, batch_size=32, method='train')\n","valid_dataloader,valid_delete = qa_preprocess(valid_df, batch_size=32, method='valid')"]},{"cell_type":"markdown","source":["# 모델 학습"],"metadata":{"id":"v3hkzTFddXJy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBn21SuQy16n"},"outputs":[],"source":["# edit distance를 이용해 자체적인 평가\n","def edit_distance(s:str, t: str):\n","    m = len(s)+1\n","    n = len(t)+1\n","    D = [[0]*m for _ in range(n)]\n","    D[0][0] = 0\n","    \n","    for i in range(1,m):\n","        D[0][i] = D[0][i-1] + 1\n","    \n","    for j in range(1,n):\n","        D[j][0] = D[j-1][0] + 1\n","    \n","    for i in range(1,n):\n","        for j in range(1,m):\n","            cost = 0\n","\n","            if s[j-1] != t[i-1]:\n","                cost = 1\n","            \n","            D[i][j] = min(D[i][j-1] + 1,D[i-1][j] + 1, D[i-1][j-1] + cost)\n","    \n","    return D[n-1][m-1]"]},{"cell_type":"code","source":["# 쿠다 캐시 메모리 정리\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"sFxuotBtndzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_YyVes5sU2i"},"outputs":[],"source":["epochs = 4\n","path = 'qa'\n","\n","optimizer = AdamW(model.parameters() , lr=1e-5, eps=1e-8)\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","score = {'loss' : [],\n","         'f1' : [],\n","         'edit_score' : []}\n","\n","for epoch in range(epochs):\n","# ==================================================================\n","#                            model train\n","# ==================================================================\n","    model.train()\n","\n","    train_loss = 0.0\n","\n","    for batchs in tqdm(train_dataloader):\n","        batch = tuple(b.to(device) for b in batchs)\n","\n","        inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","                \"start_positions\": batch[3],\n","                \"end_positions\": batch[4],\n","            }\n","\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(**inputs)\n","        \n","        loss = outputs[0]\n","        \n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_dataloader)\n","    score['loss'].append(avg_train_loss)\n","    \n","\n","    print(f'Train Loss : {avg_train_loss}')\n","\n","# ==================================================================\n","#                            model evaluation\n","# ==================================================================\n","    model.eval()\n","\n","    start_preds = []\n","    end_preds = []\n","    inputs_ids = []\n","\n","    for batchs in tqdm(valid_dataloader):\n","        batch = tuple(b.to(device) for b in batchs)\n","\n","        inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","                \"start_positions\": batch[3],\n","                \"end_positions\": batch[4],\n","            }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        start_logits = outputs['start_logits'].detach().cpu()\n","        end_logits = outputs['end_logits'].detach().cpu()\n","        \n","        inputs_ids.append(inputs['input_ids'].detach().cpu())\n","        start_preds.append(start_logits)\n","        end_preds.append(end_logits)\n","\n","    input = torch.cat(inputs_ids, dim=0).tolist()\n","    start_preds = torch.cat(start_preds, dim=0).argmax(dim=-1).tolist()\n","    end_preds = torch.cat(end_preds, dim=0).argmax(dim=-1).tolist()\n","\n","    answer = [tokenizer.decode(input[s:e+1]) for input, s, e in zip(input,start_preds,end_preds)]\n","\n","    f1 = f1_score(valid_delete.drop(valid_delete,axis=0)['answers'].tolist(), answer, average='micro')\n","\n","    pred_answers =[i.replace(tokenizer.unk_token,'') for i in answer]\n","    pred_answers =[i.replace(tokenizer.pad_token,'') for i in pred_answers]\n","    pred_answers =[i.replace(tokenizer.cls_token,'') for i in pred_answers]\n","    pred_answers =[i.replace(tokenizer.sep_token,'') for i in pred_answers]\n","    pred_answers =[i.replace('##','') for i in pred_answers]\n","\n","    edit_score = [edit_distance(i,j) for i,j in zip(valid_df.drop(valid_delete,axis=0)['answers'].tolist(),pred_answers)]\n","    edit_score = sum(edit_score)/len(edit_score)\n","\n","    score['f1'].append(f1)\n","    score['edit_score'].append(edit_score)\n","\n","    print('f1 score : ', f1)\n","    print('edit_distance : ', edit_score)\n","\n","    # 모델 저장 \n","    model.save_pretrained(f'model/{path}')\n","    tokenizer.save_pretrained(f'model/{path}')"]},{"cell_type":"markdown","metadata":{"id":"MwV_IqeMjnJY"},"source":["----"]},{"cell_type":"markdown","metadata":{"id":"-a88RX1Pyek3"},"source":["# TEST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TZx8T0ptsur"},"outputs":[],"source":["path = 'model/klue_QA_bais_batchsize_32_lr_1e-5_epoch4'\n","\n","tokenizer = BertTokenizerFast.from_pretrained(path)\n","\n","test_df,test_guid = data_load('test.json',test=True)\n","test_dataloader = qa_preprocess(test_df, method='test')\n","\n","model = BertForQuestionAnswering.from_pretrained(path)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40682,"status":"ok","timestamp":1647690383699,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"},"user_tz":-540},"id":"KEG02iU9F7n1","outputId":"3fd5277c-812a-41f6-f55b-8edab0d98fa5"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 251/251 [00:40<00:00,  6.20it/s]\n"]}],"source":["start_preds = []\n","end_preds = []\n","inputs_ids = []\n","\n","\n","for batchs in tqdm(test_dataloader):\n","    batch = tuple(b.to(device) for b in batchs)\n","\n","    inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2]\n","        }\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    start_logits = outputs['start_logits'].detach().cpu()\n","    end_logits = outputs['end_logits'].detach().cpu()\n","    \n","    inputs_ids.append(inputs['input_ids'].detach().cpu())\n","    start_preds.append(start_logits)\n","    end_preds.append(end_logits)\n","\n","input = torch.cat(inputs_ids, dim=0).tolist()\n","start_preds = torch.cat(start_preds, dim=0).argmax(dim=-1).tolist()\n","end_preds = torch.cat(end_preds, dim=0).argmax(dim=-1).tolist()\n","\n","answer = [tokenizer.decode(input[s:e+1]) for input, s, e in zip(input,start_preds,end_preds)]\n","\n","# 추가적인 후처리로 tokenizer의 토큰들 ##을 공백으로 변환\n","# 글자 길이가 20이 넘는 데이터들을 공백으로 제거함 \n","pred_answers =[i.replace(tokenizer.unk_token,'') for i in answer]\n","pred_answers =[i.replace(tokenizer.pad_token,'') for i in pred_answers]\n","pred_answers =[i.replace(tokenizer.cls_token,'') for i in pred_answers]\n","pred_answers =[i.replace(tokenizer.sep_token,'') for i in pred_answers]\n","pred_answers =[i.replace('##','') for i in pred_answers]\n","\n","sample = pd.DataFrame()\n","sample['id'] = test_guid\n","sample = pd.DataFrame()\n","sample['id'] = test_guid\n","sample['Predicted'] = pred_answers['Predicted'] = pred_answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muQ7yO1xcNq-"},"outputs":[],"source":["path = 'sample.csv'\n","sample.to_csv(f'sample/{path}', index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"01.Question Answering.ipynb","provenance":[],"authorship_tag":"ABX9TyPsEOIpErVuIO4ClVawI2vw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}